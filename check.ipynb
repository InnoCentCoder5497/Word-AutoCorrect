{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595656912823",
   "display_name": "Python 3.8.3 64-bit ('torchenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BASE_DIR = \"D:\\\\fb\\\\messages\\\\inbox\\\\MelBee_cJJkIq94Fg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(BASE_DIR, \"message_1.json\"), \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contents = []\n",
    "\n",
    "for m in data[\"messages\"]:\n",
    "    content = m.get(\"content\", None)\n",
    "    sender = \"Sahil Aggrawal\"\n",
    "    s = m.get(\"sender_name\", \"Default\")\n",
    "\n",
    "    if content and s == sender:\n",
    "        text = content.encode('ascii', 'ignore').decode('ascii')\n",
    "        html = re.sub(r\"https?://.+\", r\"\", text)\n",
    "        if len(text_l) > 0:\n",
    "            if len(html):\n",
    "                contents.append(html.lower() +  \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['babe', ',', 'am', 'almost', 'done']"
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "word_tokenize(contents[6].strip(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 2nd one is going to take some time\n\n1 1st render complete\n\n2 it's rendering\n\n3 just 10 mins\n\n4 hope you you like it\n\n5 gonna send you couple of pics i made\n\n6 babe, am almost done\n\n7 i will try my best to make an amazing portrait of you\n\n8 you the best\n\n9 thanks babe\n\n10 i was wondering if you could send me a pic of yours, which i could try to recreate\n\n11 hi babe, listen i was learning some digital art in this horrible time to protect myself from boredom.\n\n12 updated, added new chapter\n\n13 1213\n\n14 1 year, saari books khol daali \n\n15 thanku so much\n\n16 just over 1k \n\n17 psu me jaise post nikalegi tab pta chalega interview ka\n\n18 me direct interview me jaunga\n\n19 abhi apply karunga, actually mera gate clear hua hai to ab mujhe kahi b paper dene ki zarurat nahi\n\n20 nope bs paper clear hua hai abhi interview hone hai\n\n21 that's the fun na apne man se kuch b likho jaise marzi\n\n22 vocabulary doesn't matter yr, me khud bhot weird wording likhta hu\n\n23 in future am planning to allow people to write on my blog, will you be interested to write?\n\n24 sure\n\n25 me apne har social pe stories daal deta hu everytime i update my blog\n\n26  welcome\n\n27 at my blog : \n\ncomplete nahi hai post, jaise jaise read karunga book waise waise update karta rahunga\n\n28 learn the most simplest yet surprisingly powerful machine learning algorithm, the univariate linear regression.\n\n\n\n29 machine learning can do wonderful things but how do these algorithms learn? understand the most fundamental yet most important idea of optimization in my new post.\n\n\n30 understand how machine learning is changing our day to day life.\n\n\n31 please visit and give feedback on site: \n\n32 review?\n\n33 thanks \n\n34 and tell me if you think of any improvements?\n\n35 can you just go through the site: \n\n36 need a little help\n\n37 hey babe\n\n38 you sent an attachment.\n\n39 hey\n\n40 hi\n\n41 hey\n\n42 hi\n\n43 hey\n\n44  enjoy your day babe \n\n45 happy new year\n\n46 hey\n\n47 you waved at mel!\n\n48 add my number babe\n\n49 +91 94662 51645\n\n50 hey\n\n51 hello\n\n52 hi\n\n53 hey\n\n54 wassup?\n\n55 how are you\n\n56 hey\n\n57 hey\n\n58 again it's all up to you, if you want then only do it but considering these is important\n\n59 like b.pharm, b.tech in biotechnology, bds etc\n\n60 as i said any course related to medical\n\n61 consider b pharma, b.tech in biotechnology, bds or something like this\n\n62 don't get me wrong but maybe mbbs is not for you, i know that you are very passionate about it been trying for couple of years very hard but i would say staying in this very state might become dangerous for you in future\n\n63 and u know i would suggest you to change your mind about the stream you are choosing\n\n64 your life is as beautiful as you are\n\n65 don't say that babe\n\n66 like are you a regular reader for different books and like have a membership for public library\n\n67 do you read?\n\n68 bye take care\n\n69 i better go\n\n70 sry probably rums getting on my mind\n\n71 ohk\n\n72 i wish that you become happy as much as you can even if i have to negotiate my life for your happiness\n\n73 coz your happiness means a lot for them\n\n74 they do but prime thing is they want you to be happy then your blessings\n\n75 they are just secret welwishers\n\n76 lot of people think about you to be honest\n\n77 bye gud night take care\n\n78 and sorry if any of my word felt bad or hurted you\n\n79 that's my suggestion to you\n\n80 it always help\n\n81 a new hobby\n\n82 pick a hobby babe\n\n83 the more you think about it the more it saddens you\n\n84 and if anybody can do it it's not even worth considering\n\n85 i know babe but if it was easy anybody could do it\n\n86 time will never heal everything if you keep the darkness only inside and keep hold of it. leave all thoughts of your past and occupy yourself with something new and everything will automatically become fine but this will only happen if you want to heal yourself and remove all the negatives and past memories to let go from your mind and heart\n\n87 hey\n\n88 hey\n\n89 hey tumhara entrance clear ho gaya?\n\n90 hii\n\n91 hii\n\n92 heya\n\n93 hii\n\n94 wassup?\n\n95 hey\n\n96 heya\n\n97 hii\n\n98 same\n\n99 how was your day?\n\n100 ohh..kk nyc\n\n101 ssup?\n\n102 hii sexo\n\n103 sexo\n\n104 hey....ssup?\n\n105 hi\n\n106 hey\n\n107 hii\n\n108 would help\n\n109 or may be songs\n\n110 sexy imaginations\n\n111 well for that....you got the solution too in my question\n\n112 in sexy imaginations or stress?\n\n113 oh busy day han\n\n114 ssup babe\n\n115 hii\n\n116 heya\n\n117 baddy\n\n118 ssup?\n\n119 hey\n\n120 i can put my status to 'life of sakshi'\n\n121 and yeah one more thing\n\n122 appreciate it\n\n123 ohk thanks for the help\n\n124 yeah...\n\n125 and if a deadly combo?\n\n126 she looks super cute in any color so color is not a factor for her\n\n127 both\n\n128 i have to gift one to someone\n\n129 which is good?\n\n130 little help plz?\n\n131 hi\n\n132 heya\n\n133 hii\n\n134 hey\n\n135 hii\n\n136 hey\n\n137 have a wonderful day\n\n138 u say\n\n139 nthng much\n\n140 hi\n\n"
    }
   ],
   "source": [
    "for i, x in enumerate(contents):\n",
    "    print(i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['again',\n 'it',\n \"'s\",\n 'all',\n 'up',\n 'to',\n 'you',\n ',',\n 'if',\n 'you',\n 'want',\n 'then',\n 'only',\n 'do',\n 'it',\n 'but',\n 'considering',\n 'these',\n 'is',\n 'important']"
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "source": [
    "s = word_tokenize(contents[58].strip())\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['again',\n 'it',\n 'all',\n 'up',\n 'to',\n 'you',\n 'if',\n 'you',\n 'want',\n 'then',\n 'only',\n 'do',\n 'it',\n 'but',\n 'considering',\n 'these',\n 'is',\n 'important']"
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "source": [
    "[z for z in s if z.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = contents[58].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"again it's all up to you, if you want then only do it but considering these is important\""
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'again its all up to you if you want then only do it but considering these is important'"
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "re.sub(\"[\" + string.punctuation + \"]\", '', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}