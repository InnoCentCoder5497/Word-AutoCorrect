{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595849670579",
   "display_name": "Python 3.8.3 64-bit ('torchenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoCorrectusing Facebook Data\n",
    "\n",
    "## Creating vocabulary\n",
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "BASE_DIR = \"inbox\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize word counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = Counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define text cleaner\n",
    "Perform following tasks:\n",
    "- Strip special escape characters\n",
    "- remove most common punctuations\n",
    "- Remove exra spaces\n",
    "- Remove links and emojis (done in next function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.strip()\n",
    "    text = re.sub(\"([.,!?():;])\", r' ', text)\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    return re.sub(r' +', r' ', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read files function\n",
    "Reads all the chat in the json files using the json module. After reading the file, updates the word counter for each word using the global counter.update method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_content(content):\n",
    "    temp_contents = []\n",
    "    for m in content:\n",
    "        content = m.get(\"content\", None)\n",
    "        sender = \"Sahil Aggrawal\"\n",
    "        s = m.get(\"sender_name\", \"Default\")\n",
    "\n",
    "        if content and s == sender:\n",
    "            text = content.encode('ascii', 'ignore').decode('ascii')\n",
    "            html = re.sub(r\"https?://.+\", r\"\", text)\n",
    "            if len(html.split()) > 2:\n",
    "                temp_contents.append(clean_text(html.lower().strip()))\n",
    "\n",
    "    all_words = [word for sent in temp_contents for word in sent.split()]\n",
    "    word_count.update(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Vocabulary\n",
    "Loops through all the files in the folder and read all chats creating vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_folders = os.listdir(BASE_DIR)\n",
    "for i, chat in enumerate(chat_folders):\n",
    "    files = os.listdir(os.path.join(BASE_DIR, chat))\n",
    "    msg_files = list(filter(lambda x: x.startswith(\"message\"), files))\n",
    "    for msg_file in msg_files:\n",
    "        with open(os.path.join(BASE_DIR, chat, msg_file), \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        if len(data['participants']) == 2:\n",
    "            read_file_content(data['messages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate total number of words in whole of the corpus (Not Counting Unique Occurences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_words = sum(word_count.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total number of words : 466274\nTotal Number of words in Vocabulary : 20772\n"
    }
   ],
   "source": [
    "print(\"Total number of words : {}\\nTotal Number of words in Vocabulary : {}\".format(total_words, len(word_count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate probability of occurrence of each word in the given corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_dict = {}\n",
    "for word, count in word_count.items():\n",
    "    prob_dict[word] = count / total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total Number of words in Probability Dictionary : 20772\n"
    }
   ],
   "source": [
    "print(\"Total Number of words in Probability Dictionary : {}\".format(len(prob_dict)))"
   ]
  }
 ]
}